encoder_params:
  in_channels: 3
  hidden_dims: null
  latent_dim: 64


decoder_params:
  hidden_dims: null
  latent_dim: 64
  
loss_params:
  kl_coeff: null # Placeholder not actually used

vq_params:
  num_embeddings: 512
  embedding_dim: 64
  beta: 0.25

pixel_params:
  height: 16
  width: 16
  LR: 0.001
  pretrained_path: "vq_vae_celeba_conv.ckpt"
  save_path: "pixel_cnn_celeba_conv.ckpt"
  hidden_dim: 128
  num_residual_blocks: 0
  num_pixelcnn_layers: 8

exp_params:
  model_name: 'vq_vae'
  dataset: celeba
  data_path: "kaggle"
  base_model: "vqvae"
  latent_dim: 64
  checkpoint_path: "checkpoints"
  img_size: 64
  crop_size: 128
  batch_size: 256 # Better to have a square number
  LR: 0.001
  template: "vq vae"
  image_shape: 
    - 3
    - 64
    - 64

trainer_params:
  gpus: 1
  max_epochs: 30
